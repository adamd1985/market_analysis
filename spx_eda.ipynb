{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from twelvedata import TDClient\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "tqdm.pandas()\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "print(f\"API_KEY: {API_KEY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twelvedata.exceptions import BadRequestError,InternalServerError,InvalidApiKeyError,TwelveDataError\n",
    "import time\n",
    "\n",
    "def load_ts(interval, instrument, start_date, end_date, error_tolerance = 5):\n",
    "    global CURRENT_END, END_DATETIME\n",
    "    \n",
    "    CURRENT_END = end_date + '' # Copy string or referece will overwrite.\n",
    "    END_DATETIME = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    START_DATETIME = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    TOTAL_DAYS = (END_DATETIME-START_DATETIME).days\n",
    "\n",
    "    print(f\"Running for {TOTAL_DAYS}\")\n",
    "    td = TDClient(apikey=API_KEY)\n",
    "\n",
    "    def _load_data_and_update_dates(all_data, interval, instrument):\n",
    "        global CURRENT_END, END_DATETIME\n",
    "        \n",
    "        ts = td.time_series(\n",
    "                symbol=instrument,\n",
    "                interval=interval,\n",
    "                timezone=\"Europe/Malta\",\n",
    "                outputsize=5000,\n",
    "                start_date=start_date,\n",
    "                end_date=CURRENT_END\n",
    "            )\n",
    "\n",
    "        ts_df = ts.as_pandas().reset_index()\n",
    "        all_data.append(ts_df)\n",
    "        last_date = ts_df.iloc[-1]['datetime'] \n",
    "        CURRENT_END = last_date.strftime('%Y-%m-%d')\n",
    "        END_DATETIME = datetime.strptime(END, '%Y-%m-%d')\n",
    "        return all_data\n",
    "        \n",
    "\n",
    "    iters = 0\n",
    "    errors = 0\n",
    "    all_data = []\n",
    "    pbar = tqdm(desc=\"Building Timeseries\", total=TOTAL_DAYS)\n",
    "    while START_DATETIME <= END_DATETIME:\n",
    "        try:\n",
    "            all_data = _load_data_and_update_dates(all_data, interval, instrument)\n",
    "            errors = 0\n",
    "        except BadRequestError as e:\n",
    "            # these are weekends or holidays.\n",
    "            print(f\"Errors: {errors}\\nBadRequestError: {e}\")\n",
    "        except InternalServerError as e:\n",
    "            print(f\"Errors: {errors}\\nInternalServerError: {e}\")\n",
    "            errors += 1\n",
    "        except InvalidApiKeyError as e:\n",
    "            print(f\"Errors: {errors}\\nInvalidApiKeyError: {e}\")\n",
    "            errors += 1\n",
    "        except TwelveDataError as e:\n",
    "            print(f\"Errors: {errors}\\nTwelveDataError: {e}\")\n",
    "            errors += 1\n",
    "             # We might have used up all credits. Retry that day\n",
    "            time.sleep(60)\n",
    "        except Exception as e:\n",
    "            print(f\"Errors: {errors}\\nAn Exception: {e}\")\n",
    "            errors += 1\n",
    "        except:\n",
    "            print(f\"Errors: {errors}\\nUNKNOWN ERROR\")\n",
    "            errors += 1\n",
    "\n",
    "        if errors >= error_tolerance:\n",
    "            print(f\"Enough errors: {errors}, quitting the loop!\")\n",
    "            break\n",
    "\n",
    "        print(f\"End date is {CURRENT_END}\")\n",
    "        iters += 1\n",
    "        pbar.update(iters)\n",
    "\n",
    "    combined_data = None\n",
    "    if len(all_data) > 0:\n",
    "        combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    else:\n",
    "        print(\"Nothing to aggregate!\")\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUMENT_ID = \"spx\"\n",
    "INTERVAL = \"1min\" # 1min, 5min, 15min, 30min, 45min, 1h, 2h, 4h, 1day, 1week, 1month\n",
    "START = \"2020-08-10\"\n",
    "END = \"2023-08-11\"\n",
    "\n",
    "GET_CACHED = True # False \n",
    "\n",
    "if GET_CACHED:\n",
    "    file_name = f\"./ts/{INSTRUMENT_ID}-{START}-{END}-{INTERVAL}.json\"\n",
    "    # combined_data = pd.read_json(f\"./ts/{INSTRUMENT_ID}-{START}-{END}-{INTERVAL}.json\", lines=True, orient='index')\n",
    "    combined_data = pd.concat([chunk for chunk in tqdm(pd.read_json(file_name, lines=True, chunksize=1000), desc=f'Loading {file_name}')])\n",
    "else:\n",
    "    combined_data = load_ts(INTERVAL, INSTRUMENT_ID, START, END)\n",
    "    combined_data.drop_duplicates() # The provider is messy, we need to clean.\n",
    "\n",
    "if combined_data is not None:\n",
    "    if GET_CACHED is not True:\n",
    "        combined_data.to_json(f\"./ts/{INSTRUMENT_ID}-{START}-{END}-{INTERVAL}.json\", orient=\"records\", indent=1, lines=True)\n",
    "else:\n",
    "    print(\"Failed to load data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tjoe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
